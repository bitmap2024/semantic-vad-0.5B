# Semantic-vad-0.5B

本项目使用 **LoRA 方法**或**全量微调**对 Qwen2.5-0.5B-Instruct 模型进行微调，添加四个特殊 token 用于对话状态分类，实现智能对话管理。适合嵌入声学vad-asr-llm-tts的全双工语音对话架构中，修改为：
声学vad -> asr -> semantic_vad -> llm-tts 
相关论文：https://arxiv.org/pdf/2502.14145 也是这篇论文的非官方实现

## 📋 项目概述

### 特殊 Token 说明

| Token | 描述 | 应用场景 |
|-------|------|----------|
| `<\|s_s\|>` | **开始说话** | 系统处于录音状态，用户语句完整 → 系统开始响应 |
| `<\|s_l\|>` | **开始倾听** | 系统正在播放，用户有效打断 → 系统停止播放并倾听 |
| `<\|c_s\|>` | **继续说话** | 系统正在播放，背景噪音误触 → 系统继续播放 |
| `<\|c_l\|>` | **继续倾听** | 系统处于录音状态，用户语句不完整 → 系统继续等待 |


### 数据格式

训练数据采用以下JSON格式：

```json
  {
    "instruct": "你是一个智能对话状态管理器。根据User和Assistant的最近对话记录(Context)、User当前的输入(Query)、系统语音播放状态(Play_state)，判断系统的下一步行动。下一步行动可选值：<|s_s|>: 系统开始说 <|s_l|>: 系统停止播音开始听 <|c_s|>: 系统继续播音继续说 <|c_l|>: 系统继续听",
    "input": "[Context]:{\"User\": \"阿里巴巴的创始人是谁？\", \"Assistant\": \"阿里巴巴的创始人是马云，\"},[Play_state]:系统处于播音状态,[Query]:马云现在在做什么？",
    "output": "<|s_l|>"
  }
```



### 实验结果

| 真实 \ 预测 | `<\|s_s\|>` | `<\|s_l\|>` | `<\|c_s\|>` | `<\|c_l\|>` |
|-------------|-------------|-------------|-------------|-------------|
| `<\|s_s\|>` | 811         | 0           | 0           | 5           |
| `<\|s_l\|>` | 0           | 918         | 26          | 0           |
| `<\|c_s\|>` | 0           | 13          | 716         | 0           |
| `<\|c_l\|>` | 5           | 0           | 0           | 690         |

